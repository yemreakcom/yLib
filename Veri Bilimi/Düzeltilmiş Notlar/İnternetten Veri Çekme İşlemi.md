---
description: "Verilerin yuvasÄ± ğŸ’’ olan internetten verinin nasÄ±l Ã§ekileceÄŸi ğŸ•³"
---

# ğŸ•µï¸â€ Ä°nternetten Veri Ã‡ekme Ä°ÅŸlemi

## ğŸ§± Verilerin SaÄŸlamasÄ± Gereken Ã–zellikler

GÃ¼nlÃ¼k hayatta veriler istediÄŸimiz kadar basit olmaz, bunlar Ã¼zerinde iÅŸlemler yaparak uygun hale getiririz

- Tek tablodan oluÅŸan basit veya baÄŸlantÄ±lÄ± bir kaÃ§ tablodan oluÅŸan
  - FarklÄ± veriler iÃ§in *mapping* ile veri tipleri birbirine benzetilir
- Kolay analiz edilebilir formatta olan
- Makine Ã¶ÄŸrenimine sokulabilecek veriler
- DÃ¼ÅŸÃ¼k karmaÅŸÄ±klÄ±ÄŸa sahip
- YÃ¼ksek boyutlu veriler iÃ§in optimizasyon

## ğŸ—½ Veri Ã‡ekmeye GiriÅŸ

Web siteleri Ã¼zerindeki tablolarÄ± Ã§ekmek iÃ§in `pd.read_html` kullanÄ±lÄ±r

### ğŸ†” Veri Ã‡ekme SorunlarÄ± Engellemek iÃ§in `UserAgent` Ayarlama

BazÄ± websiteleri, isteklerin nereden geldiÄŸini bilmeden hareket edemezler. Bu sebeple isteÄŸi detaylandÄ±rmamÄ±z gerekmektedir.

> `HTML` alanÄ±na baÄŸlantÄ±yÄ± yazÄ±n, `pd.read_html(html)` ÅŸeklinde kullanÄ±n

```py
from urllib.request import urlopen, Request

HTML = "" # Ã–rn: https://en.wikipedia.org/

headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}
reg_url = HTML
req = Request(url=reg_url, headers=headers) 
html = urlopen(req).read() # Pandas iÃ§in kullanÄ±lacak html objesi
```

> ["[Python][Crawler]â€œHTTP Error 403: Forbiddenâ€](https://medium.com/@speedforcerun/python-crawler-http-error-403-forbidden-1623ae9ba0f)

## ğŸŒ Internetten Tablo Ã‡ekme Ã–rneÄŸi

TÃ¼m tablo verileri arasÄ±nda `0`, `1` ... deÄŸerleri ile gezinebiliriz.

```py
import pandas as pd
import json
df = pd.read_html('https://en.wikipedia.org/w/index.php?title=Fortune_Global_500&oldid=855890446', header=0)[1]
fortune_500 = json.loads(df.to_json(orient="records"))
df
```

![](../res/ex_wikipedia_tablo.png)

```py
df_list = pd.read_html("https://en.wikipedia.org/w/index.php?title=Automotive_industry&oldid=875776152", header=0)
car_totals = json.loads(df_list[1].to_json(orient="records"))
car_by_man = json.loads(df_list[3].to_json(orient='records'))
```

![](../res/ex2_wiki_tablo.png)

## ğŸ“Š Verileri Kategorize Etme

Ã‡ok yÃ¼ksek veriler ğŸ—ƒ ile baÅŸa Ã§Ä±kmak zordur.

- Kategorize iÅŸlemleri iÃ§in birebir aynÄ± metin aranmaz
- `Fuzzy Match` olan yÃ¶ntem ile Ã§ok benzeyen metinler aynÄ± gruba alÄ±nÄ±r

### ğŸ¥´ Fuzzy Match

Kelimelerin birbirine Ã§ok yakÄ±n olanlarÄ±nÄ± bulur.

```py
def fuzzy_match(word, s):
    words = set(word.split(' '))
    overlaps = [(k, len(v.intersection(words))) for k, v in s.items()]
    return max(overlaps, key=lambda x : x[1])[0]
```

```py
split_names = {i: set(i.split(' ')) for i in shares.keys()}
for i in petro_companies:
    match = fuzzy_match(i, split_names)
    print("matched {} to {}".format(i, match))
    market_share[i] = shares[match]
```
